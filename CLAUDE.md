# P-Auth RC â€” Claude Code Context

## What This Application Does

P-Auth RC is a **prior authorization (PA) readiness checker** for healthcare imaging procedures. It automates the most time-consuming part of the PA workflow: determining whether a patient chart contains sufficient clinical evidence to satisfy a payer's coverage criteria before submitting the actual PA request.

The core loop:
1. A clinic uploads a patient chart note (PDF or TXT)
2. The system loads compiled rules and an extraction schema for the requested payer/CPT combination
3. An LLM extracts structured clinical facts from the chart using that schema â€” extracting exactly the fields the rules need, nothing more
4. A deterministic rule engine compares extracted patient evidence against the compiled policy rules
5. The system outputs a readiness score, gap analysis, and actionable report

**This is clinical decision support, not clinical decision automation.** A human clinician reviews and acts on the output.

---

## Business Context

**Target customers:** Small to mid-size orthopedic clinics, sports medicine clinics, and primary care practices that order imaging (MRI, CT).

**Initial scope:** Knee MRI CPT codes (73721, 73722, 73723) for Utah Medicaid. Expand by modality and payer after first paying customer.

**GTM positioning:** Decision support tool. Improves PA submission quality and reduces denials. Not a replacement for clinical judgment or a fully automated PA system.

**Revenue model:** SaaS subscription per clinic or per PA processed.

**Compliance posture:** The application handles real PHI and must be fully HIPAA-compliant before production. See the HIPAA section below for current status and the PHI boundary that governs all LLM provider decisions.

---

## Tech Stack

| Layer | Technology |
|---|---|
| Backend API | FastAPI (Python), Uvicorn |
| LLM â€” PHI extraction (request time) | AWS Bedrock (Claude / Llama) â€” **BAA-required path; Groq is NOT acceptable here** |
| LLM â€” Policy Compiler (index-build time, no PHI) | Groq API / local Qwen2.5 â€” no BAA required, no PHI involved |
| Embeddings | SentenceTransformer (local MiniLM model) |
| Vector store | FAISS (flat inner-product index) + JSON metadata |
| Reranking | CrossEncoder (local MiniLM reranker) |
| Compiled rules store | JSON files on disk (`rag_pipeline/compiled_rules/`) |
| Data validation | Pydantic v2 |
| PDF ingestion | pdfplumber |
| Frontend | React + Vite (not yet implemented) |
| Python version | 3.11+ |

---

## The PHI Boundary â€” Read This Before Touching LLM Code

There are exactly **two LLM call sites** in this application. They have completely different compliance requirements:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POLICY COMPILER  (index-build time)                        â”‚
â”‚  Input: policy document text â€” NO PHI                       â”‚
â”‚  Output: canonical_rules.json + extraction_schema.json      â”‚
â”‚  Provider: any LLM is acceptable (Groq, public APIs, etc.)  â”‚
â”‚  File: rag_pipeline/scripts/compile_policy.py               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PATIENT EXTRACTOR  (request time)                          â”‚
â”‚  Input: patient chart text â€” CONTAINS PHI                   â”‚
â”‚  Output: structured patient field values                    â”‚
â”‚  Provider: MUST be BAA-covered (AWS Bedrock)                â”‚
â”‚            Groq is NOT acceptable here                      â”‚
â”‚  File: services/evidence.py                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Never send patient chart text to Groq or any non-BAA provider.** If you are modifying `evidence.py` or any code that passes chart text to an LLM, the provider must be AWS Bedrock (or Azure OpenAI / GCP Vertex AI with a signed BAA). If you are modifying `compile_policy.py` or any code that processes policy documents, any provider is fine.

---

## Repository Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                              # FastAPI app, CORS config
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ orchestration.py                 # POST /api/check_prior_auth (main endpoint)
â”‚   â”‚   â”œâ”€â”€ documents.py                     # Upload/list/delete policy docs
â”‚   â”‚   â””â”€â”€ authz.py                         # POST /api/compare_json_objects (standalone eval)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ evidence.py                      # Schema-driven PHI extraction (Bedrock)
â”‚   â”‚   â””â”€â”€ ingestion.py                     # File bytes â†’ text
â”‚   â”œâ”€â”€ rules/
â”‚   â”‚   â””â”€â”€ rule_engine.py                   # Deterministic PA rule evaluation (NO LLM)
â”‚   â”œâ”€â”€ rag_pipeline/
â”‚   â”‚   â”œâ”€â”€ compiled_rules/                  # OUTPUT of Policy Compiler â€” one JSON per payer/CPT
â”‚   â”‚   â”‚   â”œâ”€â”€ utah_medicaid_73721.json      #   contains canonical_rules + extraction_schema
â”‚   â”‚   â”‚   â”œâ”€â”€ utah_medicaid_73722.json
â”‚   â”‚   â”‚   â””â”€â”€ utah_medicaid_73723.json
â”‚   â”‚   â”œâ”€â”€ chunking/improved_chunker.py
â”‚   â”‚   â”œâ”€â”€ embeddings/embedder.py
â”‚   â”‚   â”œâ”€â”€ embeddings/vectorstore.py
â”‚   â”‚   â”œâ”€â”€ generation/generator.py          # MedicalGenerator: local | groq | bedrock
â”‚   â”‚   â”œâ”€â”€ generation/prompt.py
â”‚   â”‚   â”œâ”€â”€ retrieval/enhanced_retriever.py
â”‚   â”‚   â”œâ”€â”€ retrieval/enhanced_reranker.py
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”‚       â”œâ”€â”€ build_index_updated.py       # Step 1: build FAISS index (run once per policy doc)
â”‚   â”‚       â”œâ”€â”€ compile_policy.py            # Step 2: compile rules + schema (run once per policy doc)
â”‚   â”‚       â””â”€â”€ extract_policy_rules.py      # RAG retrieval â€” used for exception guidance only
â”‚   â”œâ”€â”€ data/patient_info/                   # SYNTHETIC test charts only â€” never real PHI
â”‚   â”œâ”€â”€ api_models/schemas.py                # Pydantic request/response models
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ make_report.py                   # Text report builder
â”‚       â””â”€â”€ save_json.py                     # JSON output utility
â”œâ”€â”€ uploaded_docs/                           # Runtime policy document upload directory
â””â”€â”€ requirements.txt

docs/
â”œâ”€â”€ mvp.md
â”œâ”€â”€ next_steps.md
â”œâ”€â”€ project_structure.md
â””â”€â”€ architecture_guide.md                   # Full policy-compiler architecture reference
```

### Files That No Longer Exist (Do Not Recreate)

- `normalization/normalized_custom.py` â€” deleted. Rules now come pre-compiled from `compile_policy.py`. There is no post-hoc normalization step.
- `routers/normalization.py` â€” deleted. Normalization endpoints are no longer needed.
- `routers/pa.py` and `routers/rag.py` â€” deleted. The single `/api/check_prior_auth` endpoint in `orchestration.py` replaces the separate extract/retrieve/compare flow.

---

## Key Architectural Decisions

**Why a Policy Compiler instead of runtime normalization?**
The old pipeline extracted a summary JSON from the policy (losing information), then re-parsed that summary into rules (losing more). The Policy Compiler reads the full policy document once at index-build time and produces a `canonical_rules.json` that the rule engine can evaluate directly â€” no intermediate re-interpretation. Adding a new CPT code requires running the compiler, not editing Python.

**Why schema-driven patient extraction?**
The old `evidence.py` used a hand-coded schema that had to be manually updated for every new CPT code and modality. The new approach derives the extraction schema from the compiled policy â€” the policy itself defines what fields the LLM should look for. The LLM extracts exactly the fields the rules need, nothing more.

**Why `count_gte` logic in the rule engine?**
Real payer policies use "at least 2 of the following" constructs (e.g., Utah Medicaid Section 2.4 conservative treatment). The old rule engine only supported `all` (AND) and `any` (OR), which could not express this correctly. The rule engine now supports `count_gte` and `count_lte` logic operators with a `threshold` field.

**Why are exception rules first-class objects in the rule set?**
The old architecture detected exceptions heuristically in orchestration.py. Exception rules are now part of the compiled rule set with explicit `overrides` arrays listing which standard rules they waive. This makes exception logic auditable and policy-document-driven rather than hard-coded.

**Why deterministic rule engine, not LLM for PA evaluation?**
Clinical accuracy and auditability require determinism. This is unchanged and non-negotiable. `rule_engine.py` is pure Python comparisons â€” no model involved.

**Why local models for embeddings and reranking?**
PHI must not leave the system unnecessarily. Embeddings and reranking run on local MiniLM models. RAG retrieval at request time is used only for exception guidance text, not for rule generation.

**Why FAISS over a managed vector DB?**
MVP simplicity. Known future migration point for production.

---

## Data Flow (End to End)

### Index-Build Time (runs once per policy document â€” no PHI)

```
Policy PDF/TXT
    â”œâ”€â”€â–º build_index_updated.py â€” chunks text â†’ FAISS index
    â””â”€â”€â–º compile_policy.py â€” reads full policy text
              â”‚
              â””â”€â”€â–º LLM (any provider â€” no PHI)
                        â”‚
                        â”œâ”€â”€â–º canonical_rules.json   (evaluable rule objects)
                        â””â”€â”€â–º extraction_schema.json (patient fields to extract)
                   stored in rag_pipeline/compiled_rules/{payer}_{cpt}.json
```

### Request Time (runs per patient chart submission â€” PHI present)

```
Patient Chart (PDF/TXT)
    â†“
ingestion.py â€” bytes â†’ text
    â†“
orchestration.py â€” loads compiled_rules/{payer}_{cpt}.json
    â”‚
    â”œâ”€â”€â–º extraction_schema â†’ evidence.py
    â”‚         LLM (AWS Bedrock â€” BAA required)
    â”‚         extracts exactly the fields canonical_rules need
    â”‚         â†’ patient_data dict
    â”‚
    â””â”€â”€â–º canonical_rules + patient_data â†’ rule_engine.py
              deterministic evaluation
              â†’ pass/fail per rule, score, gaps
    â†“
OrchestrationResponse â€” verdict, score, criteria, gaps, next_steps
```

---

## Compiled Rule Format

Every compiled rule set lives at `rag_pipeline/compiled_rules/{payer}_{cpt}.json`.

**Rule logic operators:**

| `logic` value | Meaning |
|---|---|
| `"all"` | All conditions must pass (AND) |
| `"any"` | At least one condition must pass (OR) |
| `"count_gte"` | At least `threshold` conditions must pass |
| `"count_lte"` | At most `threshold` conditions must pass |

**Rule flags:**

| Flag | Meaning |
|---|---|
| `"exception_pathway": true` | Rule is an exception. If it passes, rules in its `"overrides"` list are waived. |
| `"exclusion": true` | Rule is an exclusion. If the condition is NOT met, return EXCLUDED immediately without evaluating other rules. |

**Example â€” conservative treatment (count_gte):**
```json
{
  "id": "conservative_treatment",
  "description": "At least 2 of: PTâ‰¥6wks, NSAIDsâ‰¥4wks, activity mod, bracing, injection",
  "logic": "count_gte",
  "threshold": 2,
  "conditions": [
    { "field": "pt_duration_weeks",       "operator": "gte", "value": 6 },
    { "field": "nsaid_duration_weeks",    "operator": "gte", "value": 4 },
    { "field": "activity_mod_documented", "operator": "eq",  "value": true },
    { "field": "bracing_documented",      "operator": "eq",  "value": true },
    { "field": "injection_documented",    "operator": "eq",  "value": true }
  ]
}
```

**Example â€” exception rule:**
```json
{
  "id": "exception_red_flag",
  "description": "Red flag exception â€” waives conservative treatment",
  "logic": "any",
  "exception_pathway": true,
  "overrides": ["conservative_treatment"],
  "conditions": [
    { "field": "red_flag_infection_suspected", "operator": "eq", "value": true },
    { "field": "red_flag_tumor_suspected",     "operator": "eq", "value": true }
  ]
}
```

---

## Adding a New CPT Code or Payer

This requires **no Python changes**. The steps are:

```bash
# 1. Upload the policy document (existing endpoint)
POST /api/upload_document

# 2. Build the FAISS index
cd backend
python -c "from app.rag_pipeline.scripts.build_index_updated import build_index; build_index()"

# 3. Run the Policy Compiler (no PHI â€” any LLM provider is fine)
python -c "
from app.rag_pipeline.scripts.compile_policy import compile_policy
from pathlib import Path

text = Path('uploaded_docs/your_policy_file.txt').read_text()
compiled = compile_policy(text, payer='payer_id', cpt_code='73722')
print(f'{len(compiled[\"canonical_rules\"])} rules, {len(compiled[\"extraction_schema\"])} schema fields')
"

# 4. Add the entry to INDEX_MAP in orchestration.py
("payer_id", "73722"): "payer_id_73722",
```

Review the compiler output in `compiled_rules/payer_id_73722.json` before
deploying. The `_validation_errors` field in that file lists any structural
problems the compiler detected (missing fields, unknown operators, etc.).

---

## API Endpoints

| Method | Path | Purpose |
|---|---|---|
| POST | `/api/check_prior_auth` | Full PA pipeline: ingest chart â†’ extract â†’ evaluate â†’ respond |
| POST | `/api/upload_document` | Upload policy PDF/TXT for indexing |
| GET | `/api/list_uploaded_docs` | List uploaded documents |
| DELETE | `/api/delete_uploaded_doc/{filename}` | Delete a document |
| GET | `/api/list_indexes` | List available FAISS indexes |
| DELETE | `/api/delete_index/{name}` | Delete a FAISS index |
| GET | `/api/list_compiled_rules` | List available compiled rule sets |
| POST | `/api/compare_json_objects` | Standalone rule evaluation (dev/debug use) |

---

## HIPAA Compliance Status

**Current state: NOT production-ready for real PHI.**

### Open Issues

| ID | Severity | Status | Description |
|---|---|---|---|
| CRITICAL-1 | ğŸ”´ CRITICAL | Open | No encryption at rest â€” files and FAISS store are plaintext |
| CRITICAL-2 | ğŸ”´ CRITICAL | Open | CORS not environment-driven; misconfigured for production |
| CRITICAL-3 | ğŸ”´ CRITICAL | Open | No authentication on any endpoint |
| CRITICAL-4 | ğŸ”´ CRITICAL | Open | PHI sent to Groq without BAA â€” **fix: use Bedrock in `evidence.py` only; Groq remains in compiler** |
| CRITICAL-5 | ğŸ”´ CRITICAL | Open | No audit logging of PHI access â€” stub exists in `evidence.py`, needs real implementation |
| HIGH-1 | ğŸŸ  HIGH | Open | Hardcoded Windows path in `evidence.py` (`MODEL_PATH`) |
| HIGH-2 | ğŸŸ  HIGH | Open | No HTTPS/TLS configuration |
| HIGH-3 | ğŸŸ  HIGH | Open | No data retention policy |
| HIGH-4 | ğŸŸ  HIGH | Open | Path traversal vulnerability in file upload |
| HIGH-5 | ğŸŸ  HIGH | Open | No rate limiting |
| HIGH-6 | ğŸŸ  HIGH | Open | Synthetic PHI-formatted test data in repo â€” needs pre-commit hook |
| MED-1 | ğŸŸ¡ MED | Open | Tracebacks returned in HTTP error responses |
| MED-2 | ğŸŸ¡ MED | Open | No secrets validation at startup |
| MED-3 | ğŸŸ¡ MED | Open | No dependency vulnerability scanning |
| MED-4 | ğŸŸ¡ MED | Open | Global mutable state (singletons in ASGI context) |
| MED-5 | ğŸŸ¡ MED | Open | Pickle deserialization for FAISS metadata â€” replace with JSON |

### PHI Boundary Summary for LLM Provider Decisions

| Operation | PHI? | Acceptable providers |
|---|---|---|
| Policy Compiler (compile_policy.py) | No | Any â€” Groq, public APIs, local Qwen2.5 |
| Patient extraction (evidence.py) | **Yes** | AWS Bedrock, Azure OpenAI, GCP Vertex AI, local Qwen2.5 only |
| Embeddings (embedder.py) | No | Local MiniLM only (by design) |
| Reranking (enhanced_reranker.py) | No | Local MiniLM only (by design) |
| Rule evaluation (rule_engine.py) | Yes (in memory) | No external call â€” deterministic Python only |

### Compiled Rules â€” No PHI Risk

The `compiled_rules/` directory contains only policy-derived rule logic and field
definitions. It contains zero patient data and zero PHI. These files can be stored
in version control, shared freely, and backed up without HIPAA considerations. Policy
version changes are auditable as git diffs.

---

## Development Conventions

### Running the backend
```bash
cd backend
uvicorn app.main:app --reload --port 8000
```

### Environment variables required
```
GROQ_API_KEY=             # For Policy Compiler only (no PHI)
AWS_REGION=               # For Bedrock patient extraction
AWS_ACCESS_KEY_ID=        # For Bedrock (or use IAM role in production)
AWS_SECRET_ACCESS_KEY=    # For Bedrock (or use IAM role in production)
BEDROCK_MODEL_ID=         # e.g. anthropic.claude-sonnet-4-6
SENT_TRANSFORMER_MODEL=   # Path to local MiniLM model
VECTOR_STORE_PATH=        # Path to FAISS index directory
MODEL_PATH=               # Path to local Qwen2.5 (fallback only)
```

### Full index-build workflow (one-time per policy document)
```bash
cd backend

# Step 1: Build FAISS index
python -c "from app.rag_pipeline.scripts.build_index_updated import build_index; build_index()"

# Step 2: Compile rules and extraction schema
python -c "
from app.rag_pipeline.scripts.compile_policy import compile_policy
from pathlib import Path
text = Path('uploaded_docs/your_policy.txt').read_text()
compile_policy(text, payer='utah_medicaid', cpt_code='73721')
"
```

### Running tests
```bash
cd backend
python app/tests/tests_custom.py
```

### Code style rules
- All paths must use `pathlib.Path` or environment variables â€” **never hardcode absolute paths**
- Never return exception tracebacks to HTTP clients â€” log server-side only
- Patient chart text must never be passed to Groq or any non-BAA provider â€” use `provider="bedrock"` in `evidence.py`
- New API endpoints follow existing router pattern: `APIRouter` + Pydantic request/response models
- `rule_engine.py` must remain LLM-free â€” non-negotiable
- New rule logic operators (`count_gte`, `count_lte`) belong in `rule_engine.py` only â€” not in the compiler or orchestration layer
- Compiled rule files are the source of truth for what gets evaluated â€” do not add one-off rule logic in orchestration.py

### Test data
Files in `backend/app/data/patient_info/` are **synthetic test data only**. They must be clearly marked as such. Never commit real patient data. The 10 diagnostic artifacts in `api_artifacts/` are the validation ground truth for the pipeline â€” any change to the rule engine or compiler output should be checked against them.

---

## Product Roadmap Context

**Phase 1 (current):** Utah Medicaid, knee MRI (CPT 73721/22/23). Prove the compiled-rules pipeline end to end. Resolve CRITICAL HIPAA items before any real charts are processed.

**Phase 2:** Add MRI families (shoulder 73221, lumbar spine 72148, cervical spine 72141, brain 70553). Each is a compiler run + index build â€” no Python changes. Validate compiler output against known policy criteria before deploying each new CPT.

**Phase 3:** Multi-payer. Aetna as second payer. The compiler prompt is payer-agnostic â€” the same workflow applies.

**Longer term:** Real-time policy update detection, EHR integration, appeal letter generation using RAG over policy exception text.

**What we are NOT building:** A fully automated PA submission system. Human review is always in the loop.

---

## Guides (Read On Demand)

- **Full policy-compiler architecture, migration plan, HIPAA detail** â†’ `docs/architecture_guide.md`
- **Business strategy, target customers** â†’ `docs/next_steps.md`

Do not load these at session start. Read only when the conversation requires it.
