# ğŸ§± MVP Tech Stack (Example)
* Backend: FastAPI
* NLP: Clinical NER + LLM classification
* Storage: Postgres
* Security: basic HIPAA hygiene
* UI: simple form + checklist view


# 1ï¸âƒ£ High-Level Architecture (MVP) (View in edit mode)
[React Web App]
    |
    |  upload chart + select CPT + payer (optional)
    v
[FastAPI Backend]
    |
    |-- Document ingestion (PDF / text)
    |-- Evidence detection (LLM + rules)
    |-- Missing-info checklist
    |-- Justification assembly
    |
    v
[JSON PA Readiness Report]


### High-level Clarification
Chart Note (PDF / Text)
        |
        v
[1] Clinical Fact Extraction (NO RAG)
        |
        v
Structured Evidence JSON
(symptoms, duration, imaging, PT, etc.)
        |
        v
[2] Policy Criteria Retrieval (RAG)
(payer + CPT â†’ criteria snippets)
        |
        v
[3] Criteria Matching
(evidence vs criteria checklist)
        |
        v
[4] Output Generation
- readiness
- missing items
- justification (uses RAG text)

### Clarifying how AI is used here.
| Layer                | What it Understands          | AI Model Role              |
| -------------------- | ---------------------------- | -------------------------- |
| **Clinical Reality** | What happened to the patient | **Qwen extracts facts**    |
| **Insurance Rules**  | What the payer requires      | **RAG retrieves criteria** |

### Iteration upon iteration.
Chart Note
   |
   v
[1] Evidence Extraction (Qwen, NO RAG)
   |   â†’ Turns messy note into structured medical facts
   v
Structured Evidence JSON
   |
   v
[2] Policy Retrieval (RAG)
   |   â†’ Fetches payer rules from your policy vector DB
   v
Policy Criteria Snippets
   |
   v
[3] Criteria Matching (Pure Logic)
   |   â†’ Compares evidence JSON vs policy checklist
   v
Readiness Score + Missing Items
   |
   v
[4] Justification Generation (LLM + RAG text)
       â†’ Uses evidence + retrieved policy language

### âš™ï¸ Important: RAG Is Only for Policies
### Do NOT put chart notes into this vector DB.

Your vector DB should ONLY contain:
* Payer medical policies
* Coverage determination documents
* Clinical criteria bullet lists
* If you mix charts in, youâ€™ll get garbage retrieval.

### User's Perspective
1. Wrangle all the docs/pdfs/text files they can find and dump them into the evidence extraction code and create structured json object.
2. Once they have all that stuff they need to figure out which payer policy/criteria they're filling out for their patient.
3. Select the correct codes/policy/insurance company. (The indecies should already be built for them to use...)
4. They should receive a nice document with PA readiness check out of 100 with certain things highlighted and is usable.


#### Behind the scenes

* One-time setup (offline)
* Load policy PDFs
* Split into chunks (300â€“800 tokens)
* Embed chunks

Store in vector DB with metadata:
{
  "payer": "BCBS",
  "cpt_codes": ["62323", "64483"],
  "body_part": "lumbar_spine",
  "source": "BCBS_Lumbar_ESI_2025.pdf"
}

### FastAPI call
User uploads chart
        â†“
Qwen extracts facts
        â†“
You query RAG with payer + CPT (Transform it into Facts JSON for easy comparison)
        â†“
Vector DB returns matching policy rules
        â†“
Logic compares facts vs rules (deterministic rules coded by me)
        â†“
LLM writes justification using those rules

### Scalability?
Component	                Changes When?	        Needs Retraining?
Clinical extractor (Qwen)	Rarely	                âŒ
Policy RAG DB	                Every policy update	âœ… Just re-embed
Matching logic	                When rules change	âŒ
Justification writer	        Never	                âŒ

#### Another Mental Model
Step	                Brain Used	        Data Source
Evidence extraction	Qwen	                Chart
Policy retrieval	Embeddings + Vector DB	Policy PDFs
Readiness scoring	Deterministic logic	Evidence + Policy
Justification writing	LLM	                Evidence + Policy text

### Api endpoints
/api/extract_policy_rules  [POST]   - Query RAG system
/api/build_index           [POST]   - Build new index
/api/delete_index/{name}   [DELETE] - Delete index
/api/list_indexes          [GET]    - List all indexes

/api/upload_document       [POST]   - Upload document
/api/list_uploaded_docs    [GET]    - List documents
/api/delete_uploaded_doc/  [DELETE] - Delete document

/api/analyze               [POST]   - Analyze PA document (NEW)

### Backend App Structure
backend/app/
â”œâ”€â”€ main.py                 # Main app with all routers
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag.py             # RAG operations
â”‚   â”œâ”€â”€ documents.py       # Document management
â”‚   â””â”€â”€ prior_auth.py      # PA analysis (NEW)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ingestion.py
â”‚   â”œâ”€â”€ evidence.py
â”‚   â”œâ”€â”€ readiness.py
â”‚   â””â”€â”€ justification.py
â””â”€â”€ rag_pipeline/
    â””â”€â”€ scripts/
        â”œâ”€â”€ ask_question.py
        â””â”€â”€ build_index.py

### ChatGPT corrected workflow
Chart Note
   â†“
LLM â†’ Evidence Extractor
   â†“
Structured Evidence JSON
   â†“
RAG â†’ Policy Text
   â†“
LLM â†’ Policy Rule Structurer
   â†“
Structured Rule JSON
   â†“
âš™ï¸ Deterministic Logic Engine (NO LLM)
   â†“
Pass/Fail + Missing Items JSON
   â†“
LLM â†’ Human-Readable Justification

### Claude Adjusted Workflow
Chart Note
   â†“
LLM â†’ Evidence Extractor (with schema)
   â†“
Structured Evidence JSON (standardized medical entities)
   â†“
RAG Query (payer + CPT + diagnosis)
   â†“
Retrieved Policy Chunks (ranked by relevance)
   â†“
LLM â†’ Policy Rule Parser (with strict schema + few-shot examples)
   â†“
Structured Criteria JSON (normalized conditions)
   â†“
âš™ï¸ Schema Alignment Layer (map evidence fields to criteria fields)
   â†“
âš™ï¸ Rules Engine (evaluates boolean logic)
   â†“
Authorization Decision + Evidence Gap Analysis
   â†“
LLM â†’ Justification Generator (with templates)
   â†“
Human-Readable Letter


### âš ï¸ Edge Cases to Plan For
* Ambiguous policy language - "reasonable trial of PT" - how does your structurer handle this?
* Missing evidence - Patient has no documented BMI. Fail or flag for human review?
* Conflicting rules - RAG returns contradictory policy versions
* Temporal logic - "Failed treatment for at least 90 days" requires date parsing
* Negative evidence - Proving something didn't happen (no contraindications documented)

### ğŸš€ Suggested MVP Scope
Start with:
* Single payer (fewer policy variations)
* 5-10 common CPT codes
* Simple boolean AND criteria only
* Manual rule authoring (not LLM-parsed) to validate the engine first
* Then progressively add the LLM policy parser once the engine works.


### Policy Criteria Rag Pipeline
Policy PDFs â†’ Embeddings â†’ Retrieval(uses specialized query to get relevant chunks) â†’ Rerank â†’ LLM Structuring(create another prompt using the reranked specialized chunks) â†’ Policy Rules JSON
â€œI use semantic search to locate payer policy text, refine it with a relevance model, and then use an LLM to transform authoritative policy language into structured decision rules.â€

Something I just thought of is that I only have to build indecies once, as well as the payer policy json.
The thing that actually has to get created a bunch is the extracted patient notes.